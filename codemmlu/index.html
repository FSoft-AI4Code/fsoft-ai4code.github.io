<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs">
  <meta property="og:title" content="CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs"/>
  <meta property="og:description" content="Multiple Choice QA Benchmark for Assessing Code Understanding Capabilities"/>
  <meta property="og:url" content="https://fsoft-ai4code.github.io/codemmlu/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <!-- TODO: replace with CodeMMLU logo -->
  <link rel="icon" href="static/images/codemmlu-logo.png">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.0/papaparse.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/echarts@5.3.3/dist/echarts.min.js"></script>
  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@100;400&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0/dist/css/bootstrap.min.css">

  <style>
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid black;
        padding: 8px;
        text-align: center;
    }
    th[colspan="2"] {
        border-bottom: 2px solid black;
    }
    .highlight {
        font-weight: bold;
    }

    /* Interactive Leaderboard Styles */
    #content {
      width: 100%;
      max-width: 100%;
      padding: 0;
    }

    th, td {
      text-align: left;
    }

    th {
      background-color: #f2f2f2;
    }

    #notes {
      font-size: 0.75em;
      width: 100%;
      max-width: 100%;
    }

    #notes h3 {
      margin-top: 1em;
      font-size: 2em;
      text-align: left;
    }

    #notes li {
      font-size: 1.2em;
      font-weight: 300;
      margin: 1em;
    }

    .form-select {
      font-size: 1em;
    }

    table {
      table-layout: auto;
      width: 100%;
    }

    @media screen and (max-width: 1400px) {
      body {
        font-size: 1.6vw;
      }

      #content {
        width: 100%;
      }

      h1 {
        font-size: 2em;
      }

      h2 {
        font-size: 1.6em;
      }

      h3 {
        font-size: 1.2em;
      }

      table {
        font-size: medium;
      }
    }

    .btn-group-lg > .btn, .btn-lg {
      padding: 0.5rem 1rem;
      font-size: 1.25rem;
      border-radius: 0.3rem;
    }

    .btn-outline-hard {
      color: #ff6b6b;
      border: 2px solid #ff6b6b;
      background-color: transparent;
    }

    .btn-outline-hard:hover,
    .btn-check:checked + .btn-outline-hard,
    .btn-outline-hard:active {
      color: #fff;
      background-color: #ff6b6b !important;
      border-color: #ff6b6b;
    }

    .btn-outline-full {
      color: #4ecdc4;
      border: 2px solid #4ecdc4;
      background-color: transparent;
    }

    .btn-outline-full:hover,
    .btn-check:checked + .btn-outline-full,
    .btn-outline-full:active {
      color: #fff;
      background-color: #4ecdc4 !important;
      border-color: #4ecdc4;
    }
</style>
</head>
<body>


  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://fsoft-ai4code.github.io/repoexec/">
        <span class="icon">
            <i class="fas fa-home"></i>
        </span>
        </a>
        
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://fsoft-ai4code.github.io/repoexec/">
              RepoExec
            </a>
            <a class="navbar-item" href="https://fsoft-ai4code.github.io/agilecoder/">
              AgileCoder
            </a>
            <a class="navbar-item" href="https://fsoft-ai4code.github.io/srank-coderanker/">
              SRank-CodeRanker
            </a>
            <a class="navbar-item" href="https://fsoft-ai4code.github.io/codemmlu/">
              CodeMMLU
            </a>
          </div>
            
        </div>
        
      </div>
  
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://nmd2k.github.io" target="_blank">Dung Nguyen Manh<sup>1</sup></a>,</span>
                <span class="author-block">
                <a href="https://namcyan.github.io" target="_blank">Nam Le Hai<sup>1,3</sup></a>,</span>
                <span class="author-block">
                <a href="" target="_blank">Thang Phan Chau<sup>1</sup></a>,</span>
                <span class="author-block">
                <a href="" target="_blank">Thong T. Doan<sup>1</sup></a>,</span>
                <span class="author-block">
                <a href="" target="_blank">Nam V. Nguyen<sup>1</sup></a>,</span>
                <span class="author-block">
                <a href="" target="_blank">Quang Pham<sup>4</sup></a>,</span>
                <span class="author-block">
                <a href="https://bdqnghi.github.io" target="_blank">Nghi D. Q. Bui<sup>2</sup></a>
                </span>
                </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>FPT Software AI Center, <sup>2</sup>Fulbright University, Viet Nam</span>
                    <span class="author-block"><sup>3</sup>Hanoi University of Science and Technology, <sup>4</sup>VNU-HCM- University of Science, Viet Nam</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://github.com/FSoft-AI4Code/CodeMMLU/blob/main/paper/2410.01999v4.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/FSoft-AI4Code/CodeMMLU" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>GitHub</span>
                  </a>
                </span>

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2410.01999" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                  <!-- Data Link -->
                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/Fsoft-AIC/CodeMMLU" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span>&#129303; Dataset</span>
                  </a>
                </span>

                <!-- Leaderboard Link -->
                <span class="link-block">
                  <a href="#leaderboard" class="external-link button is-normal is-rounded is-dark">
                  <span>üèÜ Leaderboard</span>
                </a>

                <!-- Leaderboard Link -->
                <!-- <span class="link-block">
                  <a href="https://fsoft-ai4code.github.io/leaderboards/codemmlu/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span>üèÜ Leaderboard</span> -->
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/demo.gif" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in Code Large Language Models (CodeLLMs) have predominantly focused on open-ended code generation tasks, often neglecting the critical aspect of code understanding and comprehension. To bridge this gap, we present CodeMMLU, a comprehensive multiple-choice question-answer benchmark designed to evaluate the depth of software and code understanding in LLMs. CodeMMLU includes over 10,000 questions sourced from diverse domains, encompassing tasks such as code analysis, defect detection, and software engineering principles across multiple programming languages. Unlike traditional benchmarks, CodeMMLU assesses models' ability to reason about code rather than merely generate it, providing deeper insights into their grasp of complex software concepts and systems. Our extensive evaluation reveals that even state-of-the-art models face significant challenges with CodeMMLU, highlighting deficiencies in comprehension beyond code generation. By underscoring the crucial relationship between code understanding and effective generation, CodeMMLU serves as a vital resource for advancing AI-assisted software development, ultimately aiming to create more reliable and capable coding assistants.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            We introduce CodeMMLU, a novel benchmark designed to evaluate CodeLLMs' ability to understand and comprehend code through multi-choice question answering (MCQA). This approach enables a deeper assessment of how CodeLLMs grasp coding concepts, moving beyond mere generation capabilities. Inspired by the MMLU dataset from natural language understanding, CodeMMLU offers a robust and easily evaluable methodology with the following key features:
          </p>
          <p>
          </p>
          <p>
            <ul>
              <li><b>Comprehensiveness:</b> CodeMMLU comprises over 10,000 questions curated from diverse, high-quality sources, mitigating potential bias from limited evaluation data.</li>
              <li><b>Diversity in task, domain, and language:</b> The dataset covers a wide spectrum of software knowledge, including general QA, code generation, defect detection, and code repair across various domains and more than 10 programming languages.</li>
            </ul>
          </p>
          <p></p>
          CodeMMLU enables us to assess LLMs' capabilities in coding and software tasks from a novel perspective, extending beyond traditional code generation and completion. Our analysis reveals several notable findings: (1) previously unexplored bias issues in CodeLLMs, aligning with those observed in natural language MCQA tasks; (2) GPT-4 consistently achieving the highest average performance among closed-source models, while (3) the Meta-Llama family demonstrated the greatest accuracy among open-source models; (4) scaling laws related to model size were partially observed within the same model family but not across different families, suggesting the significant influence of pretraining datasets, methodologies, and model architectures; (5) advanced prompting techniques, such as Chain-of-Thought (CoT), consistently degraded performance, raising concerns about CodeLLMs' reasoning abilities on complex, step-by-step tasks; and (6) benchmarks like HumanEval, when converted from open-ended code generation to MCQA format, show that LLMs perform worse on MCQA, raising concerns about their real capability to understand and comprehend code. These findings highlight the current shortcomings of CodeLLMs and the intricate relationship between model architecture, training data quality, and evaluation methods in determining performance on software-related tasks.
          </p>
          <p>
          </p>
          <p>
            <b>Our key contributions are:</b>
            <ul>
              <li>We present the first MCQA benchmark for software and coding-related knowledge, addressing the need for diverse evaluation scenarios in the code domain. CodeMMLU enables the evaluation of LLMs' alignment with human inference in the software knowledge domain, similar to advancements in the NLP field.</li>
              <li>CodeMMLU provides a thorough assessment of LLM capabilities, ensuring a substantial number of samples and diversity across tasks, domains, and languages. This enables a more nuanced understanding of an LLM's strengths and weaknesses, facilitating the development of models better aligned with the complexities and demands of the software domain.</li>
              <li>Our experiments offer critical insights into LLM performance, highlighting the impact of factors such as model size, model family, and prompting techniques. This provides essential information to the community on effectively utilizing LLMs for specific tasks and domains in software engineering.</li>
            </ul>
          </p>
        </div>
        <figure>
          <img src="static/images/data-creation-flow.png", width="100%"></img>
          <figcaption><i><b>Overview of CodeMMLU data creation pipeline.</b> The blue diagram describe the process of collecting raw multiple-choice questions (MCQs) from open source internet for a knowledge testset. Otherwise, the pipeline of real-world problem indicated in orange area.</i></figcaption>
        </figure>
        <!-- <embed src="static/images/data_pipeline.pdf" width="100%"/> -->
      </div>
    </div>
  </div>
</section>



<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="leaderboard">Evaluation Results</h2>
        <div class="content has-text-justified">
          <p>
            CodeMMLU revealed significant performance differences across models, as shown in the table below. OpenAI's GPT-4o outperformed all models on CodeMMLU, demonstrating its quality across diverse tasks. Notably, despite not being the latest model, the instructed version of Meta-Llama-3-70B achieved the highest score among open-source models from 8 families. While LLMs perform well on knowledge-based tasks, they struggle with real-world problems, particularly in defect detection tasks.
          </p>
        </div>

        <!-- Interactive Leaderboard -->
        <div id="content" class="container-fluid d-flex flex-column align-items-center gap-3 px-0">
          <div class="btn-group" role="group" id="Benchmark">
            <input type="radio" class="btn-check" name="btnradio" id="Complete" checked />
          </div>
          <div id="chart" style="width: 100%; height: 600px"></div>
          <div class="container-fluid d-flex flex-row flex-nowrap px-0">
            <div class="container-fluid d-flex flex-column align-items-center px-0">
              <table id="origin" style="width: 80%" class="table table-responsive table-striped table-bordered flex-shrink-1 border border-3"></table>
            </div>
        </div>
        </div>

        <!-- Interactive Leaderboard Script -->
        <script>
          const originTable = document.getElementById("origin");
          const benchmarkRadio = document.getElementById("Benchmark");
          const chartDom = document.getElementById("chart");
          var chart = echarts.init(chartDom);

          const dataUrl = "static/data/results.json";

          var xhr = new XMLHttpRequest();
          xhr.open("GET", dataUrl, false);
          xhr.send();

          const calcAverage = (a, b) => {
            if (a == null || b == null) {
              return null;
            } else {
              return parseFloat(((parseFloat(a) + parseFloat(b)) / 2).toFixed(1));
            }
          };

          var data;
          if (xhr.status === 200) {
            data = JSON.parse(xhr.responseText);
            data = Object.keys(data).map((key) => {
              return {
                Model: key,
                ...data[key],
              };
            });
          } else {
            alert("Failed to load data from results.json");
          }
          const globalData = data;

          const clearTable = () => {
            originTable.innerHTML = "";
          };

          const clearChart = () => {
            chartOption.xAxis.data = [];
            chartOption.series[0].data = [];
            chartOption.series[1].data = [];
            chartOption.series[0].markLine.data = [];
            chartOption.series[1].markLine.data = [];
          };

          var chartOption = {
            legend: {
              data: ["base", "instructed"],
              itemStyle: {
                opacity: 1.0,
              },
            },
            grid: {
              left: "1%",
              right: "4%",
              bottom: "3%",
              containLabel: true,
            },
            xAxis: {
              name: "Size",
              type: "category",
              boundaryGap: false,
              data: [],
              axisLabel: {
                formatter: function (value) {
                  return value + "B";
                },
              },
            },
            yAxis: {
              name: "CodeMMLU Acc (%)",
              type: "value",
              show: true,
              nameTextStyle: {
                align: "left",
              },
              splitLine: {
                show: true,
                lineStyle: {
                  color: "gray",
                  type: "dashed",
                },
              },
            },
            tooltip: {
              trigger: "item",
              axisPointer: {
                type: "cross",
              },
            },
            series: [
              {
                name: "base",
                type: "scatter",
                data: [],
                itemStyle: {
                  color: "#91cc75",
                  opacity: 0.2,
                },
                emphasis: {
                  focus: "series",
                },
                lineStyle: {
                  width: 2,
                },
                markLine: {
                  symbol: "none",
                  lineStyle: {
                    type: "solid",
                    width: 1
                  },
                  label: {
                    show: true,
                    position: "insideEndTop",
                    formatter: function (params) {
                      return params.data.name;
                    },
                    fontSize: 12,
                    color: "#91cc75"
                  },
                  emphasis: {
                    disabled: true,
                    lineStyle: {
                      width: 1
                    }
                  },
                  data: [],
                },
              },
              {
                name: "instructed",
                type: "scatter",
                data: [],
                itemStyle: {
                  color: "#5470c6",
                  opacity: 0.2,
                },
                emphasis: {
                  focus: "series",
                },
                lineStyle: {
                  width: 2,
                },
                markLine: {
                  symbol: "none",
                  lineStyle: {
                    type: "solid",
                    width: 1
                  },
                  label: {
                    show: true,
                    position: "insideEndTop",
                    formatter: function (params) {
                      return params.data.name;
                    },
                    fontSize: 12,
                    color: "#5470c6"
                  },
                  emphasis: {
                    disabled: true,
                    lineStyle: {
                      width: 1
                    }
                  },
                  data: [],
                },
              },
            ],
          };

          const theaders = ["Model", "Size (B)", "Syntactic Acc", "Semantic Acc", "Fundamental-task Acc", "CodeMMLU"];

          const displayTable = (table, score) => {
            data = globalData
              .filter((row) => {
                return row["pass@1"][score] != null;
              })
              .sort((a, b) => {
                return b["pass@1"][score] - a["pass@1"][score];
              });
          
            var thead = document.createElement("thead");
            var headerRow = document.createElement("tr");
            var th = document.createElement("th");
            th.textContent = "#";
            headerRow.appendChild(th);
            
            theaders.forEach(function (header) {
              var th = document.createElement("th");
              th.textContent = header;
              if (header == "CodeMMLU") {
                th.style.backgroundColor = "#EEFFEE";
              }
              if (header == "Size (B)") {
                th.style.backgroundColor = "#FFFFD4";
              }
              headerRow.appendChild(th);
            });
            thead.appendChild(headerRow);
            table.appendChild(thead);
          
            var tbody = document.createElement("tbody");
            var previousScore = null;
            var actualRank = 1;
          
            data.forEach((row, index) => {
              var dataRow = document.createElement("tr");
              var rankCell = document.createElement("td");
          
              if (row["pass@1"][score] !== previousScore) {
                actualRank = index + 1;
                previousScore = row["pass@1"][score];
              }
          
              rankCell.textContent = actualRank;
              dataRow.appendChild(rankCell);
          
              var modelCell = document.createElement("td");
              if (actualRank == 1) {
                modelCell.textContent = "ü•á ";
              } else if (actualRank == 2) {
                modelCell.textContent = "ü•à ";
              } else if (actualRank == 3) {
                modelCell.textContent = "ü•â ";
              } else {
                modelCell.textContent = "";
              }
              var modelLink = document.createElement("a");
              modelLink.href = row["link"];
              modelLink.textContent = row["Model"];
              modelLink.classList.add("link-underline-primary");
              modelLink.classList.add("text-nowrap");
              modelCell.appendChild(modelLink);
              modelCell.classList.add("d-flex");
              modelCell.classList.add("flex-nowrap");
              dataRow.appendChild(modelCell);

              var sizeCell = document.createElement("td");
              sizeCell.textContent = row["size"] ? row["size"] : "-";
              sizeCell.style.backgroundColor = "#FFFFD4";
              dataRow.appendChild(sizeCell);

              var syntacticCell = document.createElement("td");
              syntacticCell.textContent = row["syntactic_accuracy"] || "-";
              dataRow.appendChild(syntacticCell);

              var semanticCell = document.createElement("td");
              semanticCell.textContent = row["semantic_accuracy"] || "-";
              dataRow.appendChild(semanticCell);

              var rtaskCell = document.createElement("td");
              rtaskCell.textContent = row["realtask_accuracy"] || "-";
              dataRow.appendChild(rtaskCell);

              var passCell = document.createElement("td");
              passCell.classList.add("text-nowrap");
              passCell.textContent = row["pass@1"][score];
              passCell.style.backgroundColor = "#EEFFEE";
              passCell.style.fontWeight = "bold";
              dataRow.appendChild(passCell);
              tbody.appendChild(dataRow);
            });
            table.appendChild(tbody);
          };

          const displayChart = (score) => {
            let data = globalData
              .filter((model) => {
                return model["pass@1"][score] != null;
              })
              .sort((a, b) => {
                return b["pass@1"][score] - a["pass@1"][score];
              });

            const sizeList = [
              ...new Set(
                data
                  .filter((model) => model["size"] != null)
                  .map((model) => Math.round(model["size"])),
              ),
            ].sort((a, b) => {
              return a - b;
            });

            chartOption.xAxis.data = sizeList;
            chartOption.yAxis.max =
              1 + Math.max(...data.map((model) => model["pass@1"][score]));

            const nonPromptedModels = data.filter(
              (model) => model["prompted"] == false,
            );
            const promptedModels = data.filter(
              (model) => model["prompted"] == true,
            );

            [nonPromptedModels, promptedModels].forEach((series, idx) => {
              series.forEach((model) => {
                if (model["size"] == null) {
                  chartOption.series[idx].markLine.data.push({
                    name: model["Model"],
                    yAxis: model["pass@1"][score],
                  });
                } else {
                  chartOption.series[idx].data.push({
                    name: model["Model"],
                    value: [`${Math.round(model["size"])}`, model["pass@1"][score]],
                  });
                }
              });
            });

            const offsets = [[50, 0]]
              .concat(Array.from({ length: sizeList.length - 2 }, () => [0, 0]))
              .concat([[-50, 0]]);
            sizeList.forEach((size, idx) => {
              const bestNonPromptedModel = nonPromptedModels
                .filter((model) => Math.round(model["size"]) == size)
                .sort((a, b) => {
                  return b["pass@1"][score] - a["pass@1"][score];
                })[0];
              const bestPromptedModel = promptedModels
                .filter((model) => Math.round(model["size"]) == size)
                .sort((a, b) => {
                  return b["pass@1"][score] - a["pass@1"][score];
                })[0];
              const hightLightBest = (series, model) => {
                const point = chartOption.series[series].data.find(
                  (point) => point.name == model["Model"],
                );
                point.itemStyle = {
                  opacity: 1.0,
                };
                point.label = {
                  show: true,
                  position: "top",
                  offset: offsets[idx],
                  formatter: function (params) {
                    return params.data.name;
                  },
                  color: "inherit",
                };
              };
              if (bestNonPromptedModel) {
                hightLightBest(0, bestNonPromptedModel);
              }
              if (bestPromptedModel) {
                hightLightBest(1, bestPromptedModel);
              }
            });

            chart.setOption(chartOption);
          };

          const completeRadio = document.getElementById("Complete");

          completeRadio.addEventListener("click", function () {
            clearTable();
            displayTable(originTable, "complete");
            clearChart();
            displayChart("complete");
          });

          completeRadio.click();

          window.addEventListener("resize", () => {
            chart.resize();
          });
        </script>
      </div>
    </div>
  </div>

</section>


<!-- Notes Section -->
<section class="section" id="notes">
  <div class="container is-max-desktop">
    <h3>üìù Notes</h3>
    <div class="inline-block mt-3 px-3">
      <u1>
        <li>Evaluated using <a href="https://github.com/FSoft-AI4Code/CodeMMLU">CodeMMLU</a></li>
        <li>Models are ranked according to Accuracy using greedy decoding.</li>
        <li>"Size" here is the amount of activated model weight during inference.</li>
      </u1>
      <!-- <ol>
        <li>Evaluated using <a href="https://github.com/FSoft-AI4Code/CodeMMLU">CodeMMLU</a></li>
        <li>Models are ranked according to Accuracy using greedy decoding.</li>
        <li>"Size" here is the amount of activated model weight during inference.</li>
      </ol> -->
    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{dung2024codemmlu,
  title={CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs},
  author={Manh, Dung Nguyen and Chau, Thang Phan and Hai, Nam Le and Doan, Thong T and Nguyen, Nam V and Pham, Quang and Bui, Nghi DQ},
  journal={arXiv preprint arXiv:2410.01999v1},
  year={2024}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content", style="text-align: center;">
          <img src="static/images/aic_logo.png", width="120px">
          <p>
            <h5>Contact us</h5>
            <a href="https://www.fpt-aicenter.com/ai-residency/">üåê fpt-aicenter</a>
            <a href="mailto:support.ailab@fpt.com">‚ìÇÔ∏è support.ailab@fpt.com</a>
          </p>
        </div>
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the&nbsp;<a href="https://nerfies.github.io" target="_blank">Nerfies</a>&nbsp;project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>
</html>
